import os
import re
import json
import pickle
import time
from pathlib import Path
from urllib.parse import urlparse, parse_qs

import requests
from bs4 import BeautifulSoup
import ddddocr  # uv add ddddocr
from configparser import ConfigParser


BASE = "https://course.fcu.edu.tw"
COOKIE_FILE = Path("cookies.pkl")
SESSION_META = Path("session.json")


def save_response_to_file(filename, content):
    with open(filename, "w", encoding="utf-8") as f:
        f.write(content)
    print(f"âœ… ç¶²é å…§å®¹å·²å„²å­˜åˆ° {filename}")


def _parse_tb_ids(raw: str) -> list[str]:
    """æ”¯æ´é€—è™Ÿ/ç©ºç™½/æ›è¡Œæˆ– JSON é™£åˆ—ï¼Œå›å‚³å»é‡å¾Œçš„æœ‰åºæ¸…å–®"""
    raw = (raw or "").strip()
    if not raw:
        return []
    ids: list[str] = []
    if raw.startswith("["):
        try:
            arr = json.loads(raw)
            ids = [str(x).strip() for x in arr if str(x).strip()]
        except Exception:
            pass
    if not ids:
        # ä»¥é€—è™Ÿã€ç©ºç™½ã€æ›è¡Œåˆ‡åˆ†
        tokens = re.split(r"[,\s]+", raw)
        ids = [t.strip() for t in tokens if t.strip()]
    # å»é‡ä¿åº
    seen = set()
    dedup: list[str] = []
    for x in ids:
        if x not in seen:
            seen.add(x)
            dedup.append(x)
    return dedup


def load_config(path: str | Path = "config.ini"):
    """è®€å– config.ini å–å¾— NIDã€PASSã€tbSubIDs(list) ä»¥åŠé‡è©¦è¨­å®š"""
    cfg = ConfigParser()
    default_path = (
        Path(__file__).with_name("config.ini")
        if "__file__" in globals()
        else Path(path)
    )
    target = default_path if default_path.exists() else Path(path)
    if not cfg.read(target, encoding="utf-8"):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¨­å®šæª”ï¼š{target.resolve()}")
    try:
        nid = cfg.get("auth", "NID").strip()
        pwd = cfg.get("auth", "PASS").strip()
        tb_raw = ""
        if cfg.has_option("course", "tbSubIDs"):
            tb_raw = cfg.get("course", "tbSubIDs")
        elif cfg.has_option("course", "tbSubID"):
            tb_raw = cfg.get("course", "tbSubID")  # ä»ç›¸å®¹å–®å€¼æˆ–å¤šå€¼å­—ä¸²
        tb_ids = _parse_tb_ids(tb_raw)

        # è®€å–é‡è©¦è¨­å®š
        retry_enabled = cfg.getboolean("retry", "enabled", fallback=False)
        retry_count = cfg.getint("retry", "count", fallback=3)
        retry_interval = cfg.getint("retry", "interval", fallback=30)

        if not nid or not pwd or not tb_ids:
            raise ValueError("NID / PASS / tbSubIDs ä¸èƒ½ç‚ºç©º")
        return nid, pwd, tb_ids, retry_enabled, retry_count, retry_interval
    except Exception as e:
        raise ValueError(f"è¨­å®šæª”å…§å®¹ä¸å®Œæ•´æˆ–æ ¼å¼éŒ¯èª¤ï¼š{e}")


def make_session():
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/139.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "Accept-Language": "zh-TW,zh;q=0.9",
        "Accept-Encoding": "gzip, deflate, br",
        "Sec-Ch-Ua": '"Chromium";v="139", "Not;A=Brand";v="99"',
        "Sec-Ch-Ua-Mobile": "?0",
        "Sec-Ch-Ua-Platform": '"macOS"',
        "Sec-Fetch-Dest": "document",
        "Sec-Fetch-Mode": "navigate",
        "Sec-Fetch-Site": "same-origin",
        "Sec-Fetch-User": "?1",
        "Upgrade-Insecure-Requests": "1",
        "Connection": "keep-alive",
        "Origin": BASE,
        "Referer": f"{BASE}/",
        "Cache-Control": "max-age=0",
        "Content-Type": "application/x-www-form-urlencoded",
        "Priority": "u=0, i",
    }
    s = requests.Session()
    s.headers.update(headers)
    return s


def load_cookies_if_any(session: requests.Session) -> bool:
    if not COOKIE_FILE.exists():
        return False
    try:
        with open(COOKIE_FILE, "rb") as f:
            session.cookies = pickle.load(f)
        return True
    except Exception:
        return False


def load_session_meta():
    if not SESSION_META.exists():
        return None
    try:
        return json.loads(SESSION_META.read_text(encoding="utf-8"))
    except Exception:
        return None


def save_session_meta(guid: str, lang: str, base: str):
    SESSION_META.write_text(
        json.dumps({"guid": guid, "lang": lang, "base": base}, ensure_ascii=False),
        encoding="utf-8",
    )


def is_login_page(html: str) -> bool:
    return ('id="ctl00_Login1_UserName"' in html) or ("Login.aspx" in html)


def is_session_timeout(html: str) -> bool:
    return (
        ("Session å·²é€¾æ™‚" in html)
        or ("è«‹é‡æ–°ç™»å…¥" in html)
        or ("error.aspx?code" in html)
    )


def validate_session(
    session: requests.Session, guid: str, lang: str, base: str
) -> bool:
    url = f"{base}/AddWithdraw.aspx?guid={guid}&lang={lang}"
    resp = session.get(url, allow_redirects=True)
    text = resp.text
    if (
        resp.url.endswith("Login.aspx")
        or is_login_page(text)
        or is_session_timeout(text)
    ):
        return False
    soup = BeautifulSoup(text, "html.parser")
    vs = soup.find("input", {"name": "__VIEWSTATE"})
    btn = soup.find(
        "input", {"name": "ctl00$MainContent$TabContainer1$tabSelected$btnGetSub"}
    )
    return bool(vs and btn)


def do_login(session: requests.Session, nid: str, pwd: str):
    session.get(f"{BASE}/")
    cap = session.get(f"{BASE}/validateCode.aspx")
    with open("captcha.jpg", "wb") as f:
        f.write(cap.content)
    ocr = ddddocr.DdddOcr()
    with open("captcha.jpg", "rb") as f:
        captcha = ocr.classification(f.read())
    print("è‡ªå‹•è­˜åˆ¥é©—è­‰ç¢¼:", captcha)

    r = session.get(f"{BASE}/Login.aspx")
    soup = BeautifulSoup(r.text, "html.parser")
    viewstate = soup.find("input", {"name": "__VIEWSTATE"}).get("value", "")
    viewstategenerator = soup.find("input", {"name": "__VIEWSTATEGENERATOR"}).get(
        "value", ""
    )
    eventvalidation = soup.find("input", {"name": "__EVENTVALIDATION"}).get("value", "")

    login_data = {
        "__EVENTTARGET": "ctl00$Login1$LoginButton",
        "__EVENTARGUMENT": "",
        "__LASTFOCUS": "",
        "__VIEWSTATE": viewstate,
        "__VIEWSTATEGENERATOR": viewstategenerator,
        "__VIEWSTATEENCRYPTED": "",
        "__EVENTVALIDATION": eventvalidation,
        "ctl00$Login1$RadioButtonList1": "zh-tw",
        "ctl00$Login1$UserName": nid,
        "ctl00$Login1$Password": pwd,
        "ctl00$Login1$vcode": captcha,
    }
    resp = session.post(f"{BASE}/Login.aspx", data=login_data, allow_redirects=True)
    print("ç™»å…¥å¾Œè·³è½‰URL:", resp.url)
    if resp.url.endswith("Login.aspx") or is_login_page(resp.text):
        raise RuntimeError("ç™»å…¥å¤±æ•—ï¼Œå¯èƒ½æ˜¯é©—è­‰ç¢¼æˆ–å¸³å¯†éŒ¯èª¤")

    parsed = urlparse(resp.url)
    base_after = f"{parsed.scheme}://{parsed.netloc}"
    guid = parse_qs(parsed.query).get("guid", [None])[0]
    lang = parse_qs(parsed.query).get("lang", [None])[0]

    if not guid or not lang:
        test = session.get(f"{base_after}/AddWithdraw.aspx", allow_redirects=True)
        p2 = urlparse(test.url)
        guid = parse_qs(p2.query).get("guid", [guid])[0]
        lang = parse_qs(p2.query).get("lang", [lang])[0]

    if not guid or not lang:
        raise RuntimeError("ç™»å…¥æˆåŠŸä½†ç„¡ guid/langï¼Œæµç¨‹ä¸­æ­¢")

    with open(COOKIE_FILE, "wb") as f:
        pickle.dump(session.cookies, f)
    save_session_meta(guid, lang, base_after)
    print("ç™»å…¥å¾Œ cookies å·²å„²å­˜åˆ° cookies.pklï¼Œguid/lang/base å·²å¯«å…¥ session.json")
    return guid, lang, base_after


def get_hidden_fields(html: str, dump_name: str = "last_page.html"):
    soup = BeautifulSoup(html, "html.parser")

    def val(name):
        el = soup.find("input", {"name": name})
        return el.get("value", "") if el else ""

    vs = val("__VIEWSTATE")
    vg = val("__VIEWSTATEGENERATOR")
    ev = val("__EVENTVALIDATION")
    if not (vs and vg and ev):
        Path(dump_name).write_text(html, encoding="utf-8")
        raise RuntimeError("é é¢ç¼ºå°‘å¿…è¦éš±è—æ¬„ä½ï¼Œå·²è½æª”åˆ° " + dump_name)
    return vs, vg, ev


def find_add_event_args(html: str) -> list[str]:
    """è§£æé é¢ä¸­æ‰€æœ‰ addCourse$Nï¼Œå›å‚³å¦‚ ['addCourse$0','addCourse$1', ...]ï¼Œä¾åºä¸”å»é‡"""
    nums = re.findall(r"addCourse\$(\d+)", html)
    seen = set()
    ordered = []
    for n in nums:
        arg = f"addCourse${n}"
        if arg not in seen:
            seen.add(arg)
            ordered.append(arg)
    return ordered


def main(stop_check_func=None):
    config_result = load_config()
    NID, PASS, TB_SUB_IDS, RETRY_ENABLED, RETRY_COUNT, RETRY_INTERVAL = config_result
    session = make_session()

    have_cookies = load_cookies_if_any(session)
    meta = load_session_meta() or {}
    guid, lang, base = meta.get("guid"), meta.get("lang"), meta.get("base")

    if (
        have_cookies
        and guid
        and lang
        and base
        and validate_session(session, guid, lang, base)
    ):
        print("âœ… æ—¢æœ‰ cookies æœ‰æ•ˆï¼Œç›´æ¥ä½¿ç”¨ç¾æœ‰ç™»å…¥ç‹€æ…‹")
    else:
        print("âš ï¸ æ—¢æœ‰ cookies ä¸å¯ç”¨æˆ–ç¼ºå°‘ guid/lang/baseï¼ŒåŸ·è¡Œä¸€èˆ¬ç™»å…¥")
        guid, lang, base = do_login(session, NID, PASS)

    add_withdraw_url = f"{base}/AddWithdraw.aspx?guid={guid}&lang={lang}"

    # å¦‚æœå•Ÿç”¨é‡è©¦ï¼Œå‰‡é€²è¡Œå¤šè¼ªé‡è©¦
    if RETRY_ENABLED:
        if RETRY_COUNT == 0:
            print(f"âœ… å•Ÿç”¨ç„¡é™é‡è©¦åŠŸèƒ½ï¼Œæ¯æ¬¡é–“éš” {RETRY_INTERVAL} ç§’")
        else:
            print(
                f"âœ… å•Ÿç”¨è‡ªå‹•é‡è©¦åŠŸèƒ½ï¼Œå°‡é‡è©¦ {RETRY_COUNT} æ¬¡ï¼Œæ¯æ¬¡é–“éš” {RETRY_INTERVAL} ç§’"
            )

        retry_round = 0
        while True:
            if stop_check_func and stop_check_func():
                print("âš ï¸ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œä¸­æ–·é‡è©¦")
                break

            retry_round += 1
            if RETRY_COUNT == 0:
                print(f"\n===== ç¬¬ {retry_round} è¼ªé‡è©¦ ï¼ˆç„¡é™é‡è©¦æ¨¡å¼ï¼‰=====")
            else:
                print(f"\n===== ç¬¬ {retry_round} è¼ªé‡è©¦ =====")

            all_success = process_course_selection(
                session, add_withdraw_url, TB_SUB_IDS, stop_check_func
            )

            if all_success:
                print(f"ğŸ‰ æ‰€æœ‰èª²ç¨‹é¸èª²æˆåŠŸï¼")
                break

            # æª¢æŸ¥æ˜¯å¦é”åˆ°é‡è©¦æ¬¡æ•¸é™åˆ¶ï¼ˆ0 è¡¨ç¤ºç„¡é™é‡è©¦ï¼‰
            if RETRY_COUNT > 0 and retry_round >= RETRY_COUNT:
                print("âŒ é‡è©¦æ¬¡æ•¸å·²é”ä¸Šé™ï¼Œé¸èª²çµæŸ")
                break

            # ç­‰å¾…é–“éš”æ™‚é–“
            if RETRY_INTERVAL > 0:
                print(f"â³ ç­‰å¾… {RETRY_INTERVAL} ç§’å¾Œé€²è¡Œä¸‹ä¸€è¼ªé‡è©¦...")
                for i in range(RETRY_INTERVAL):
                    if stop_check_func and stop_check_func():
                        print("âš ï¸ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œä¸­æ–·ç­‰å¾…")
                        return
                    time.sleep(1)
            else:
                # é–“éš”ç‚º 0 ç§’ï¼Œä½†ä»éœ€çŸ­æš«å»¶é²é¿å…éå¿«é‡è©¦
                if stop_check_func and stop_check_func():
                    print("âš ï¸ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œä¸­æ–·é‡è©¦")
                    return
                time.sleep(0.1)  # 100ms çš„æœ€å°å»¶é²
    else:
        # ä¸å•Ÿç”¨é‡è©¦ï¼ŒåŸ·è¡Œå–®æ¬¡é¸èª²
        process_course_selection(session, add_withdraw_url, TB_SUB_IDS, stop_check_func)

    print("\n===== é¸èª²çµæŸ =====")


def process_course_selection(
    session, add_withdraw_url, TB_SUB_IDS, stop_check_func=None
):
    """è™•ç†èª²ç¨‹é¸èª²ï¼Œè¿”å›æ˜¯å¦å…¨éƒ¨æˆåŠŸ"""
    all_success = True

    # é€ç§‘è™•ç†
    for idx, sub_id in enumerate(TB_SUB_IDS, start=1):
        if stop_check_func and stop_check_func():
            print("âš ï¸ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œåœæ­¢é¸èª²")
            return False

        print(f"\n===== ç¬¬ {idx} ç§‘ï¼š{sub_id} =====")

        # é€²å…¥é é¢æ‹¿åˆå§‹éš±è—æ¬„ä½
        r = session.get(add_withdraw_url, allow_redirects=True)
        if is_session_timeout(r.text) or is_login_page(r.text):
            print("âš ï¸ æœƒè©±å¤±æ•ˆï¼Œéœ€è¦é‡æ–°ç™»å…¥")
            all_success = False
            continue

        vs, vg, ev = get_hidden_fields(r.text, dump_name=f"aw_{sub_id}_page.html")

        # æŸ¥è©¢è©²ç§‘
        query_data = {
            "ctl00_ToolkitScriptManager1_HiddenField": "",
            "ctl00_MainContent_TabContainer1_ClientState": '{"ActiveTabIndex":1,"TabState":[true,true]}',
            "__EVENTTARGET": "",
            "__EVENTARGUMENT": "",
            "__LASTFOCUS": "",
            "__VIEWSTATE": vs,
            "__VIEWSTATEGENERATOR": vg,
            "__VIEWSTATEENCRYPTED": "",
            "__EVENTVALIDATION": ev,
            "ctl00$MainContent$TabContainer1$tabSelected$tbSubID": sub_id,
            "ctl00$MainContent$TabContainer1$tabSelected$btnGetSub": "æŸ¥è©¢",
            "ctl00$MainContent$TabContainer1$tabSelected$cpeWishList_ClientState": "false",
        }
        r = session.post(add_withdraw_url, data=query_data)
        vs, vg, ev = get_hidden_fields(r.text, dump_name=f"aw_{sub_id}_query.html")

        # æ‰¾å‡ºæ‰€æœ‰å¯åŠ é¸åˆ—çš„ __EVENTARGUMENT
        event_args = find_add_event_args(r.text)
        if not event_args:
            print("æ‰¾ä¸åˆ°å¯åŠ é¸æŒ‰éˆ•ï¼Œå¯èƒ½æŸ¥ç„¡èª²æˆ–æœªé–‹æ”¾ã€‚")
            # é¡¯ç¤ºé é¢è¨Šæ¯
            soup = BeautifulSoup(r.text, "html.parser")
            msg = soup.find(
                "span",
                {"id": "ctl00_MainContent_TabContainer1_tabSelected_lblMsgBlock"},
            )
            if msg:
                print("è¨Šæ¯ï¼š", msg.get_text(strip=True))
            all_success = False
            continue

        success = False
        for ea in event_args:
            if stop_check_func and stop_check_func():
                print("âš ï¸ æ”¶åˆ°åœæ­¢ä¿¡è™Ÿï¼Œåœæ­¢é¸èª²")
                return False

            add_data = {
                "ctl00_ToolkitScriptManager1_HiddenField": "",
                "ctl00_MainContent_TabContainer1_ClientState": '{"ActiveTabIndex":1,"TabState":[true,true]}',
                "__EVENTTARGET": "ctl00$MainContent$TabContainer1$tabSelected$gvToAdd",
                "__EVENTARGUMENT": ea,  # ä¾‹å¦‚ addCourse$0
                "__LASTFOCUS": "",
                "__VIEWSTATE": vs,
                "__VIEWSTATEGENERATOR": vg,
                "__VIEWSTATEENCRYPTED": "",
                "__EVENTVALIDATION": ev,
                "ctl00$MainContent$TabContainer1$tabSelected$tbSubID": sub_id,
                "ctl00$MainContent$TabContainer1$tabSelected$cpeWishList_ClientState": "false",
            }
            r = session.post(add_withdraw_url, data=add_data)

            soup = BeautifulSoup(r.text, "html.parser")
            msg = soup.find(
                "span",
                {"id": "ctl00_MainContent_TabContainer1_tabSelected_lblMsgBlock"},
            )
            text = msg.get_text(strip=True) if msg else "(ç„¡è¨Šæ¯)"
            print(f"è¨Šæ¯ï¼š{text}")

            # æˆåŠŸé—œéµè©è‡ªè¡Œèª¿æ•´
            if any(k in text for k in ("æˆåŠŸ", "å·²åŠ é¸", "å®Œæˆ")):
                success = True
                break

            # æ›´æ–°éš±è—æ¬„ä½ä»¥ä¾¿å˜—è©¦ä¸‹ä¸€åˆ—
            try:
                vs, vg, ev = get_hidden_fields(
                    r.text, dump_name=f"aw_{sub_id}_after_{ea}.html"
                )
            except Exception:
                # è‹¥é é¢è·³é›¢æˆ–ç¼ºæ¬„ä½å°±ä¸­æ­¢æ­¤ç§‘
                break

        if not success:
            print(f"â†’ ç§‘ç›® {sub_id} æœªæˆåŠŸåŠ é¸ã€‚")
            all_success = False

    return all_success


if __name__ == "__main__":
    main()
